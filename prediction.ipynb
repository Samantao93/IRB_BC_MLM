{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b92f77-7841-46dc-9e11-f5fbaaf2e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar librerias\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167bea69-b333-4775-aaa0-3ee2618b0963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "df=pd.read_spss('DB.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550278b8-c262-4c02-9e24-25bdad61db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variables para transformar en categóricas\n",
    "cols = [\"TIPO_HIST\",\"FENOTIPO\",\"TvsS\",\"NECR\",\"INVA\",\"GANGLIOS\",\"RECIDIVA\",\"SIT_ACTUAL\"]\n",
    "\n",
    "for col in cols:\n",
    "    df[col] = df[col].astype(\"category\")\n",
    "    df[f\"{col}_CAT\"] = df[col].cat.codes.replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1032a2-f91e-4087-895c-55de23879b49",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60db0a43-8a71-4519-91d9-96882f21ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_dfs(df, columna):\n",
    "    \"\"\"\n",
    "    Filtra el DataFrame basado en los valores especificados en la columna.\n",
    "    \n",
    "    :param df: DataFrame de entrada.\n",
    "    :param columna: Columna resultado.\n",
    "    :return: Dos DataFrames (uno con todas las citoquinas y otro con las significativas).\n",
    "    \"\"\"\n",
    "    # Filtramos las columnas interesantes (Individual cytokine names have been anonymized as ‘cytokines’ to preserve confidentiality)\n",
    "    columnas_total=['EDAD', 'TAMAÑO', 'GDIF2CAT', 'LUM_NO_LUM', 'KI67','TILS', 'SLE','SG', 'cytokines', 'TIPO_HIST_CAT','FENOTIPO_CAT', 'TvsS_CAT', 'NECR_CAT', 'INVA_CAT', 'GANGLIOS_CAT', 'RECIDIVA_CAT', 'SIT_ACTUAL_CAT']\n",
    "    \n",
    "    # Filtramos las columnas interesantes (Individual cytokine names have been anonymized as ‘cytokines’ to preserve confidentiality)\n",
    "    columnas_cito = ['cytokines'] + [columna]\n",
    "\n",
    "    # Filtramos las columnas interesantes (resultado de VolcanoPlot; Individual cytokine names have been anonymized as ‘cytokines_volcano_plot’ to preserve confidentiality)\n",
    "    columnas_seleccion = ['cytokines_volcano_plot'] + [columna]\n",
    "\n",
    "\n",
    "    df_todo = df[columnas_total]\n",
    "    df_cito = df[columnas_cito]\n",
    "    df_seleccion = df[columnas_seleccion]\n",
    "    return df_todo, df_cito, df_seleccion\n",
    "\n",
    "# Función para target binario (TvsS_CAT y LUM_NO_LUM)\n",
    "def train_model_binary(df, columna):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa modelos de Machine Learning (RandomForest, XGBoost y LightGBM).\n",
    "    \n",
    "    :param df: DataFrame de entrada con los datos.\n",
    "    :param columna: Columna objetivo.\n",
    "    \"\"\"\n",
    "    # Eliminar los NA de la columna resultado\n",
    "    df=df.dropna(subset=[columna])\n",
    "    \n",
    "    # Separar features y target     \n",
    "    X = df.drop(columns=[columna])\n",
    "    y = df[columna]\n",
    "    \n",
    "    # Dividir en conjunto de entrenamiento y prueba (80/20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(f'Tamaño entrenamiento {len(X_train)}')\n",
    "    print(f'Tamaño entrenamiento {len(X_test)}')\n",
    "    \n",
    "    # Definir hiperparámetros\n",
    "    rf_model = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "    xgb_model = xgb.XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "    lgb_model = lgb.LGBMClassifier(n_estimators=100, random_state=42, verbose=-1)\n",
    "    \n",
    "    models = {'Random Forest': rf_model, 'XGBoost': xgb_model, 'LightGBM': lgb_model}\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Entrenando {model_name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Evaluación del modelo\n",
    "        print(f\"{model_name} - Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "        print(f\"{model_name} - AUC-ROC Score:\", roc_auc_score(y_test, y_pred))\n",
    "        \n",
    "        # Matriz de Confusión\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=set(y), yticklabels=set(y))\n",
    "        plt.title(f'{model_name} - Matriz de Confusión')\n",
    "        plt.show()\n",
    "        \n",
    "        # Cálculo de métricas adicionales\n",
    "        TP = conf_matrix[1, 1] if conf_matrix.shape == (2, 2) else 0\n",
    "        TN = conf_matrix[0, 0] if conf_matrix.shape == (2, 2) else 0\n",
    "        FP = conf_matrix[0, 1] if conf_matrix.shape == (2, 2) else 0\n",
    "        FN = conf_matrix[1, 0] if conf_matrix.shape == (2, 2) else 0\n",
    "        \n",
    "        if conf_matrix.shape == (2, 2):\n",
    "            accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "            ppv = TP / (TP + FP) if (TP + FP) > 0 else 0  # Valor Predictivo Positivo\n",
    "            npv = TN / (TN + FN) if (TN + FN) > 0 else 0  # Valor Predictivo Negativo\n",
    "            sensibilidad = TP / (TP + FN) if (TP + FN) > 0 else 0  # Sensibilidad\n",
    "            especificidad = TN / (TN + FP) if (TN + FP) > 0 else 0  # Especificidad\n",
    "            riesgo = (TP / (TP + FN)) / (FP / (FP + TN)) if (FP + TN) > 0 and (TP + FN) > 0 else 0  # Odds ratio\n",
    "            \n",
    "            # Imprimir KPIs\n",
    "            print(f\"{model_name} - Accuracy: {accuracy:.4f}\")\n",
    "            print(f\"{model_name} - PPV (Positive Predictive Value): {ppv:.4f}\")\n",
    "            print(f\"{model_name} - NPV (Negative Predictive Value): {npv:.4f}\")\n",
    "            print(f\"{model_name} - Sensibilidad (Recall): {sensibilidad:.4f}\")\n",
    "            print(f\"{model_name} - Especificidad: {especificidad:.4f}\")\n",
    "            print(f\"{model_name} - Riesgo (Odds Ratio): {riesgo:.4f}\")\n",
    "        \n",
    "        # Importancia de características\n",
    "        feature_importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        \n",
    "        # Visualización de importancia de variables\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x=feature_importances[:20], y=feature_importances.index[:20], hue=feature_importances.index[:20], palette='viridis', dodge=False, legend=False)\n",
    "        plt.title(f\"{model_name} - Importancia de Variables (Top 20)\")\n",
    "        plt.xlabel(\"Importancia\")\n",
    "        plt.ylabel(\"Variables (Proteínas)\")\n",
    "        plt.show()\n",
    "    \n",
    "    return models\n",
    "\n",
    "# Función para target multiple (FENOTIPO_CAT)\n",
    "def train_model_multi(df, columna):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa modelos de Machine Learning (RandomForest, XGBoost y LightGBM).\n",
    "    \n",
    "    :param df: DataFrame de entrada con los datos.\n",
    "    :param columna: Columna objetivo con categoría múltiple.\n",
    "    \"\"\"\n",
    "    X = df.drop(columns=[columna])  # variables independientes\n",
    "    y = df[columna]                 # variable dependiente\n",
    "    \n",
    "    # División de datos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Definición de modelos (hiperparámetros)\n",
    "    models = {\n",
    "        \"RandomForest\": RandomForestClassifier(n_estimators=500, random_state=42),\n",
    "        \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "        \"LightGBM\": lgb.LGBMClassifier(n_estimators=100, random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Entrenamiento, predicción y evaluación\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n--- {name} ---\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        try:\n",
    "            auc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "            print(f\"AUC: {auc:.4f}\")\n",
    "        except:\n",
    "            pass \n",
    "        \n",
    "        # Matriz de confusión\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f\"{name} - Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.show()\n",
    "    \n",
    "        # Importancia de características (solo para modelos basados en árboles)\n",
    "        feature_importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        feature_importances[:20].plot(kind='barh', title=f\"{name} - Top 20 Features\", figsize=(8, 6))\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3ae730-a7b8-4934-add1-2a0e8e930f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tvss, df_cito_tvss, df_tvss_seleccion = crear_dfs(df, 'TvsS_CAT')\n",
    "df_lum, df_cito_lum, df_lum_seleccion = crear_dfs(df, 'LUM_NO_LUM')\n",
    "df_fen, df_cito_fen,df_fen_seleccion = crear_dfs(df, 'FENOTIPO_CAT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c029f077-f20d-4193-b267-9e29d8d6ef6f",
   "metadata": {},
   "source": [
    "# TvsS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f95be85-60d4-45fb-bd64-66316f86c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_binary(df_tvss, 'TvsS_CAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649f0c3e-92c3-4df7-b8b2-40ea81fe78c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_binary(df_cito_tvss, 'TvsS_CAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efeec1d-992b-4819-a33d-9bc9f9754fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_binary(df_tvss_seleccion, 'TvsS_CAT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86a3d8f-1fe2-45ee-a63a-9b8d0d5e08e2",
   "metadata": {},
   "source": [
    "# Luminal vs No Luminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac98e80c-2ffc-4532-a316-da5825d990e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_binary(df_lum, 'LUM_NO_LUM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e79bb-a73c-4767-adb5-9c73e91c75c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_binary(df_cito_lum, 'LUM_NO_LUM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf8d6c9-5298-4dc4-b8e6-d9c8489c6f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_binary(df_lum_seleccion, 'LUM_NO_LUM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61beb4e9-e467-441d-99a9-91f2d93a0732",
   "metadata": {},
   "source": [
    "# Fenotipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c3464a-3347-4b4d-920a-82c48f3e552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_multi(df_fen, 'FENOTIPO_CAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b06d9ce-cf07-4e9f-8e21-aef23c3c26b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_multi(df_cito_fen, 'FENOTIPO_CAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe5a7a4-e1f5-44d9-9544-3a44f69c46f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_multi(df_fen_seleccion, 'FENOTIPO_CAT')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
